{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfxiSjWR8Kmw"
   },
   "source": [
    "![arangodb](https://github.com/joerg84/ArangoDBUniversity/blob/master/img/ArangoDB_logo.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VE3KR8sW8Kmw"
   },
   "source": [
    "# Fuzzy Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3DiEFJE8Kmx"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/joerg84/ArangoDBUniversity/blob/master/FuzzySearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4o7Vn4Uo8Kmy"
   },
   "source": [
    "[ArangoSearch](https://www.arangodb.com/why-arangodb/full-text-search-engine-arangosearch/) provides information retrieval features, natively integrated into ArangoDB’s query language and with support for all data models. It is primarily a full-text search engine, a much more powerful alternative to the full-text index type.\n",
    "Check this [ArangoSearch notebook](https://colab.research.google.com/github/joerg84/ArangoDBUniversity/blob/master/ArangoSearch.ipynb) for an introduction to ArangoSearch.\n",
    "\n",
    "When dealing with real-world text retrieval, we often not only care about exact matches to our search phrase but need to consider for example typos or alternative spellings.\n",
    "“Fuzzy search” is an umbrella term referring to a set of algorithms for such approximate matching. Usually such algorithms evaluate some similarity measure showing how close a search term is to the items in a dictionary. Then a search engine can make a decision on which results have to be shown first.\n",
    "\n",
    "In this notebook we will apply at two different implementation of fuzzy search in [ArangoSearch](https://www.arangodb.com/why-arangodb/full-text-search-engine-arangosearch/):\n",
    "* [Levenshtein distance](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#levenshtein_match\n",
    ")\n",
    "* [NGram similarity](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#ngram_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlcbVfOs8Kmy"
   },
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uoIFBPwp8Kmy"
   },
   "source": [
    "Before getting started with ArangoSearch we need to prepare our environment and create a temporary database on ArangoDB's managed Service Oasis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXdL1FZe8Kmz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/joerg84/ArangoDBUniversity.git\n",
    "!rsync -av ArangoDBUniversity/ ./ --exclude=.git\n",
    "!pip3 install pyarango\n",
    "!pip3 install \"python-arango>=5.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pKXjdTS8Km2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import oasis\n",
    "import time\n",
    "\n",
    "from pyArango.connection import *\n",
    "from arango import ArangoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6968hvSs8Km3"
   },
   "source": [
    "Create the temporary database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "TaGHLin28Km4",
    "outputId": "e8c04d0b-5720-4882-a028-0f6f0b40616a"
   },
   "outputs": [],
   "source": [
    "# Retrieve tmp credentials from ArangoDB Tutorial Service\n",
    "login = oasis.getTempCredentials(tutorialName=\"FuzzyArangoSearch\", credentialProvider=\"https://de64d9dc6b66.arangodb.cloud:8529/_db/_system/tutorialDB/tutorialDB\")\n",
    "\n",
    "# Connect to the temp database\n",
    "# Please note that we use the python-arango driver as it has better support for ArangoSearch \n",
    "database = oasis.connect_python_arango(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "ECAfpWU48Km6",
    "outputId": "e4ce37ef-fd3d-4f43-c0b0-9dc6f241632f"
   },
   "outputs": [],
   "source": [
    "print(\"https://\"+login[\"hostname\"]+\":\"+str(login[\"port\"]))\n",
    "print(\"Username: \" + login[\"username\"])\n",
    "print(\"Password: \" + login[\"password\"])\n",
    "print(\"Database: \" + login[\"dbName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZ0mydlq8Km8"
   },
   "source": [
    "Feel free to use to above URL to checkout the ArangoDB WebUI!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vXqUK6L8Km9"
   },
   "source": [
    "##  IMDB Example Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9JQShDi8Km9"
   },
   "source": [
    "![imdb](https://github.com/joerg84/ArangoDBUniversity/blob/master/img/IMDB_graph.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXkaey-g8Km9"
   },
   "source": [
    "Last, but not least we will import the [IMBD Example Dataset](https://github.com/arangodb/example-datasets/tree/master/Graphs/IMDB) including information about various movies, actors, directors, ... as a graph. \n",
    "*Note the included arangorestore will only work on Linux or Windows systems, if you want to run this notebook on a different OS please consider using the appropriate arangorestore from the [Download area](https://www.arangodb.com/download-major/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKM6jcXa8Km-"
   },
   "source": [
    "## Linux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "colab_type": "code",
    "id": "VPqigG8H8Km-",
    "outputId": "8c5a5acd-1a2b-44be-d208-2bcbeb1733a9"
   },
   "outputs": [],
   "source": [
    "! ./tools/arangorestore -c none --server.endpoint http+ssl://{login[\"hostname\"]}:{login[\"port\"]} --server.username {login[\"username\"]} --server.database {login[\"dbName\"]} --server.password {login[\"password\"]} --default-replication-factor 3  --input-directory \"data/imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yE_uMym8KnA"
   },
   "source": [
    "# Create First View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhQynyJJ8KnB"
   },
   "source": [
    "As discussed above, an ArangoSearch view contains references to documents stored in different collections. \n",
    "This makes it possible to perform complex federated searches, even over a complete graph including vertex and edge collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "B-koXo6C8KnB",
    "outputId": "0e75b79a-5036-4a26-bbf9-1479b123be8e"
   },
   "outputs": [],
   "source": [
    "# Create an ArangoSearch view.\n",
    "database.create_arangosearch_view(\n",
    "    name='v_imdb'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dn3rKYKG8KnD"
   },
   "source": [
    "Let us check it is actually there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J5bwOthX8KnD",
    "outputId": "9fca1911-1b7b-4afe-d2ea-bff6093b09c3"
   },
   "outputs": [],
   "source": [
    "print(database[\"v_imdb\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a7RJtPcu8KnF"
   },
   "source": [
    "Next, we will create a [custom analyzer](https://www.arangodb.com/docs/stable/arangosearch-analyzers.html) to preprocess the values.\n",
    "Note that, in order to support ngram similarity the analyzer must have at least the \"position\" and \"frequency\" features enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SSfISdj8kpd6",
    "outputId": "9418895a-fd3b-44b9-ad1e-7c9474d158d8"
   },
   "outputs": [],
   "source": [
    "# Delete in case analyzer existed before\n",
    "database.delete_analyzer('fuzzy_search_analyzer', ignore_missing=True)\n",
    "\n",
    "database.create_analyzer(\n",
    "        name='fuzzy_search_analyzer',\n",
    "        analyzer_type='ngram',\n",
    "        properties={  \n",
    "        \"min\": 2,  \n",
    "        \"max\": 2,  \n",
    "        \"preserveOriginal\": False \n",
    "        }, \n",
    "        features=[\"position\", \"frequency\"] \n",
    "    )\n",
    "\n",
    "# Retrieve list of analyzers.\n",
    "print(database.analyzers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EiCHaBtl4gkZ"
   },
   "source": [
    "Next, we need to link the view and our custom analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "IL8GQTtQ8KnF",
    "outputId": "a1b5dbc2-16f5-4094-9034-fa5ac2a5ca44"
   },
   "outputs": [],
   "source": [
    " link = { \n",
    "  \"includeAllFields\": True,\n",
    "  \"fields\" : { \n",
    "      \"title\" : { \"analyzers\" : [ \"fuzzy_search_analyzer\", \"text_en\"] },\n",
    "      \"description\" : { \"analyzers\" : [ \"fuzzy_search_analyzer\", \"text_en\"] }\n",
    "      }\n",
    "}\n",
    "\n",
    "\n",
    "database.update_arangosearch_view(\n",
    "    name='v_imdb',\n",
    "    properties={'links': { 'imdb_vertices': link }}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMZumewz8KnH"
   },
   "source": [
    "As the indexing might take a few seconds, let us have a brief look at what is actually going on.\n",
    "\n",
    "When you link a collection you can choose which individual fields to link or specify to link all fields. It might be helpful to think about linking fields in the same way you think about indexing attributes, although not exactly the same. When you link data to a view it is indexed in a way that allows for quick retrieval. This process also stores the data in a way that allows for the ArangoSearch-specific AQL functions to perform unique queries such as tokenizing, stemming, removing stop words, and as we will see in this notebook complex matching functions.\n",
    "\n",
    "An additional benefit and a difference to typical indexing is that you are able to link multiple collections to one view and apply the desired analyzers. The image below shows how the collections are linked, analyzed and then made available via the view. When performing queries you can use all the typical AQL functions against a view, the same way that you would with a collection name. Though, the real benefit comes when using ArangoSearch-specific functions and you start taking advanatage of features such as ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89Xus7i28KnI"
   },
   "source": [
    "![ArangoSearch](https://github.com/joerg84/ArangoDBUniversity/blob/master/img/ArangoSearch_Arch.jpg?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8LsVW-LNIIU"
   },
   "source": [
    "By now our view should be ready, so let us issue the first test query and look for short Drama Movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "53oLsRFJNIZV",
    "outputId": "8f89a4bd-22ef-4766-c5b8-a6aa66bb95b6"
   },
   "outputs": [],
   "source": [
    "cursor = database.aql.execute(\n",
    "  \"\"\"\n",
    "  FOR d IN v_imdb \n",
    "    SEARCH d.type == \"Movie\" \n",
    "    AND \n",
    "    d.genre == \"Drama\" \n",
    "    AND \n",
    "    d.runtime IN 10..50 \n",
    "    RETURN d.title\n",
    "  \"\"\"\n",
    ")\n",
    "# Iterate through the result cursor\n",
    "for doc in cursor:\n",
    "  print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFhVZYhcSejU"
   },
   "source": [
    "If we set up everything correctly there should be 18 results, containing movies such as:\n",
    "  * Frühlings Erwachen - Eine Kindertragödie\n",
    "  * Glastage\n",
    "  * Sunday in August"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kInsH7LYSiEF"
   },
   "source": [
    "Now that we have finished some of the setup, let's move on to the functions that make up Fuzzy search. \n",
    "As mentioned in the beginning of this notebook, Fuzzy search comes in the form of various [NGram similarity](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#ngram_match) and [Levenshtein distance](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#levenshtein_match\n",
    ") AQL functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SF3oT3gQfbB0"
   },
   "source": [
    "# NGram Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haexui4sDce2"
   },
   "source": [
    "Ngram similarity is a measure for the difference between two strings represented by counting how long the longest sequence of matching ngrams is, divided by target’s total ngram count. To better understand this concept let's start with a simple example. The below query compares the phrase `quick fox` to the similar phrase of `quick foxx` (additional `x`). These are similar phrases and as such, they should have a high ngram similarity. \n",
    "\n",
    "Go ahead and execute the query below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t4-VhEhgC6oM",
    "outputId": "7b850752-ffe4-4e01-e806-f7a25d5f756e"
   },
   "outputs": [],
   "source": [
    "cursor = database.aql.execute(\n",
    "\"\"\"\n",
    "RETURN NGRAM_SIMILARITY(\n",
    "\"quick fox\",\n",
    "\"quick foxx\", \n",
    "2)\"\"\"\n",
    ")\n",
    "# Iterate through the result cursor\n",
    "for doc in cursor:\n",
    "  print(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dWKNe-uiDhov"
   },
   "source": [
    "With a ngram size of 2, the ngram similarity between both strings is 0.888. Feel free experiment with other combinations such as `NGRAM_SIMILARITY( \"same string\",\"same string\", 2)` or vary the ngramSize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQlOtFJCfglL"
   },
   "source": [
    "With a ngram size of 2, the ngram similarity between both strings is 0.888, the closer the similarity is to 1 the more similar they are. Feel free experiment with other combinations such as `NGRAM_SIMILARITY( \"same string\",\"same string\", 2)` or vary the ngramSize.\n",
    "\n",
    "Ngram functions such as this break apart the words using the supplied ngram size, 2 in our query above. This means that the function compares the two words broken up into their 2 letter ngrams:\n",
    "\n",
    "  ```\n",
    "  quick fox         --         quick foxx\n",
    "  ----------------------------------------\n",
    "  qu                --         qu (match)\n",
    "  ui                --         ui (match)\n",
    "  ic                --         ic (match)\n",
    "  ck                --         ck (match)\n",
    "  k                 --         k  (match)\n",
    "   f                --          f (match)\n",
    "  fo                --         fo (match)\n",
    "  ox                --         ox (match)\n",
    "  x                 --         xx (do not match)\n",
    "  ```\n",
    "If we use simple math here we can see that there is around an 85% match when an extra `x` is supplied. However, N-Gram Similarity and Distance is not as simple as this, but hopefully this provides a quick intro to the basic concept of ngram matching and similarity. If you would like to take a deep dive into this topic, a paper published by [Grzegorz Kondrak at the University of Alberta](https://webdocs.cs.ualberta.ca/~kondrak/papers/spire05.pdf) is a great resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POtg36jBTh5r"
   },
   "source": [
    "While [NGRAM_SIMILARITY()](https://www.arangodb.com/docs/devel/aql/functions-string.html#ngram_similarity) only counts fully matching ngrams, [NGRAM_POSITIONAL_SIMILARITY()](https://www.arangodb.com/docs/devel/aql/functions-string.html#ngram_positional_similarity) also considers partially matching ones. Let us look at how that effects the returned scores. \n",
    "In this first example we are comparing `NGRAM_SIMILARITY` and `NGRAM_POSITIONAL_SIMILARITY` scores using the same two phrases as with our previous  example. These phrases are so similar that counting partial matches doesn't make any difference, thus we get the same scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g1Uj0IBbTlmR",
    "outputId": "52bd47b5-d81f-4dab-91a4-cbbafebf3088"
   },
   "outputs": [],
   "source": [
    "cursor = database.aql.execute(\n",
    "\"\"\"\n",
    "RETURN\n",
    "{\"NGRAM_SIMILARITY\" : NGRAM_SIMILARITY(\n",
    "\"quick fox\",\n",
    "\"quick foxx\", \n",
    "3),\n",
    "\"NGRAM_POSITIONAL_SIMILARITY\" : NGRAM_POSITIONAL_SIMILARITY(\n",
    "\"quick fox\",\n",
    "\"quick foxx\", \n",
    "3)}\"\"\"\n",
    ")\n",
    "# Iterate through the result cursor\n",
    "for doc in cursor:\n",
    "  print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "izAPzIB8Tpw4"
   },
   "source": [
    "If we start to change a few more letters in the phrases, the differences between the two functions becomes more clear. The score for `NGRAM_POSITIONAL_SIMILARITY` is nearly double that of `NGRAM_SIMILARITY`, due to the fact that it counted the partial matches. This provides us with some additional 'fuzziness' by allowing the matching requirement to be a bit more lenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b1CgLWTeTtSF",
    "outputId": "21934bae-285c-42fb-f413-0be957912c57"
   },
   "outputs": [],
   "source": [
    "cursor = database.aql.execute(\n",
    "\"\"\"\n",
    "RETURN\n",
    "{\"NGRAM_SIMILARITY\" : NGRAM_SIMILARITY(\n",
    "\"quick fox\",\n",
    "\"quirky foxx\", \n",
    "3),\n",
    "\"NGRAM_POSITIONAL_SIMILARITY\" : NGRAM_POSITIONAL_SIMILARITY(\n",
    "\"quick fox\",\n",
    "\"quirky foxx\", \n",
    "3)}\"\"\"\n",
    ")\n",
    "# Iterate through the result cursor\n",
    "for doc in cursor:\n",
    "  print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9KCiOw0TwSE"
   },
   "source": [
    "Depending on your requirements, the decision to count partially matching ngrams adds some 'fuzziness' that may help provide some context to your searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4bZtMbZyT4Qn"
   },
   "source": [
    "[NGRAM_SIMILARITY](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#ngram_similarity) and [NGRAM_POSITIONAL_SIMILARITY](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#ngram_positional_similarity) are two new functions that come with ArangoDB 3.7 and can be used to improve text searches but have a drawback of not being able to utilize the indexing benefits of views. They are still very powerful string functions and can offer a lot of functionality for text queries.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## Ngram Match\n",
    "\n",
    "However, [NGRAM_MATCH](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#ngram_match) is able to use the indexing of ArangoSearch views and is what we will look at next.\n",
    "\n",
    "Let us start by using the [NGRAM_MATCH](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#ngram_match) function to find a mispelled movie title. This should return multiple Star Wars movies, let's take a moment to understand why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "b9_f99xRfvcZ",
    "outputId": "bf74ec60-d7cf-40ab-b95f-78b61fdb836d"
   },
   "outputs": [],
   "source": [
    "cursor = database.aql.execute(\n",
    "\"\"\"\n",
    "FOR d IN v_imdb SEARCH NGRAM_MATCH(d.description, 'galxy', 0.7, 'fuzzy_search_analyzer')\n",
    "SORT BM25(d) DESC  \n",
    "RETURN {\n",
    "  \"Title\" : d.title,\n",
    "  \"Description\": d.description}\"\"\"\n",
    ")\n",
    "# Iterate through the result cursor\n",
    "for doc in cursor:\n",
    "  print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9XsTF8Mtfwaj"
   },
   "source": [
    "The `NGRAM_MATCH` syntax follows typical ArangoSearch function structure. You first supply the field you would like to search, the search term(s), and then the next value is the threshold amount which must be between `0.0` and `1.0`, last is the analyzer to use on the search terms. The `.7` threshold amount is the new addition and is how much ‘fuzziness’ we are still considering to be a match.\n",
    "\n",
    "The similarity is calculated by counting how long the longest sequence of matching ngrams is, divided by the target’s total ngram count. Only fully matching ngrams are counted.\n",
    "\n",
    "The analyzer we used was configured with a min and max of 2, which means it looks at words 2 letters at a time. This is useful for determining the longest common sequence and context. The idea behind n-gram matching is searching for similar words, but not necessarily exact matches. One of the simplest ways of calculating similarity between two words is calculating the longest common sequence (LCS) of letters. The longer the LCS is the more similar the words are. However, this approach has one big disadvantage – absence of context. For example, words <connection> and <fonetica> have a long LCS (o-n-e-t-i) but very different meanings. To add some context, ngram sequences are used.\n",
    "\n",
    "Each word is split into a series of letter groups and these groups are then matched. If we use the same words, but calculate similarity based on 3-grams, an ngram with max and min of 3, we will get a better similarity measure: con-onn-nne-nec-ect-cti-tio-ion vs. fon-one-net-eti-tic-ica gives shorter LCS ( zero matches). To get rid of length differences we normalize the LCS length by word length. We calculate these matches to get a rating with a value between 0 (no match at all) and 1(fully matched). \n",
    "\n",
    "Increasing the ngram size is not always the best choice due to it also increasing the accuracy requirement of the search. Scores would be much lower for the above Star Wars search if we had chosen an ngram size of 3. We would need to decrease our threshold requirement which can have the impact of returning less relevant results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUgcAWSpdl8l"
   },
   "source": [
    "# Levenshtein MATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JisqzP5dflN"
   },
   "source": [
    "[Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) is a another measure for the difference between two strings represented by the  minimum number of single-character transformations required to move from one string to the other. Let is consider a concrete example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pr-gqDa8de1I",
    "outputId": "62b2a707-6cb9-4902-fa5f-f48ffbe83c56"
   },
   "outputs": [],
   "source": [
    "cursor = database.aql.execute(\n",
    "\"\"\"\n",
    "RETURN LEVENSHTEIN_DISTANCE(\n",
    "\"The quick brown fox jumps over the lazy dog\", \n",
    "\"The quick black dog jumps over the brown fox\")\"\"\"\n",
    ")\n",
    "# Iterate through the result cursor\n",
    "for doc in cursor:\n",
    "  print(doc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0r1uwBXLBaMk"
   },
   "source": [
    "Here we need a minimum of 13 transformations to move from one string to the other. \n",
    "Feel free to find a minimum sequence for this transformation or experiment with other combinations such as `LEVENSHTEIN_DISTANCE(\"a\", \"b\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IYzxDnGn8KnM",
    "outputId": "8ce1a052-fae8-4bab-9bb1-71d6395af2db"
   },
   "outputs": [],
   "source": [
    "# Execute the query\n",
    "cursor = database.aql.execute(\n",
    "  \"\"\"\n",
    "  FOR d IN v_imdb\n",
    "    SEARCH ANALYZER(LEVENSHTEIN_MATCH(\n",
    "      d.description, \n",
    "      'galxy', \n",
    "      2\n",
    "      ), \n",
    "    \"text_en\")\n",
    "    SORT BM25(d) DESC \n",
    "    RETURN {\n",
    "    \"Title\" : d.title,\n",
    "    \"Description\": d.description}\"\"\")\n",
    "# Iterate through the result cursor\n",
    "for doc in cursor:\n",
    "  print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKymkZji51Go"
   },
   "source": [
    "# Comparison \n",
    "\n",
    "With these two options when should you use which?\n",
    "\n",
    "Levenstein Distance is in most cases a good default choice when dealing with individual words as it deals well with typos.\n",
    "In case of phrases, ngram is a good default choice as it keeps more context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWpH7oVb8KnW"
   },
   "source": [
    "# Further Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dP0KpLrK8KnW"
   },
   "source": [
    "* https://www.arangodb.com/docs/stable/arangosearch.html\n",
    "\n",
    "* https://www.arangodb.com/arangodb-training-center/search/arangosearch/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "FuzzySearch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
